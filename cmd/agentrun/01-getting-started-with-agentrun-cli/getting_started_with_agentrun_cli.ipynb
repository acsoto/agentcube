{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Getting Started with AgentRun CLI\n\n## Overview\n\nIn this tutorial, you will learn how to use **AgentRun CLI** to develop, package, build, and deploy AI agents to AgentCube. AgentRun CLI is a comprehensive developer tool that streamlines the complete agent lifecycle from local development to cloud deployment.\n\nWe will walk through a practical example using a **LangChain Agent** that provides tool-calling capabilities with Calculator and Weather tools via FastAPI.\n\n### Tutorial Details\n\n| Information         | Details                                                                      |\n|:--------------------|:-----------------------------------------------------------------------------|\n| Tutorial type       | Practical/Hands-on                                                           |\n| Agent type          | LangChain-based API Service                                                  |\n| Framework           | LangChain + FastAPI                                                          |\n| Language            | Python 3.8+                                                                  |\n| Tutorial components | Local development, packaging, building, publishing, and invoking agents      |\n| Tutorial vertical   | Cross-vertical                                                               |\n| Example complexity  | Beginner-friendly                                                            |\n| Tools used          | AgentRun CLI, Docker, LangChain                                              |\n\n### What You'll Learn\n\n* How to structure an AI agent project\n* How to use AgentRun CLI commands (`pack`, `build`, `publish`, `invoke`, `status`)\n* How to configure agent metadata\n* How to build and deploy agents to AgentCube\n* Best practices for agent development\n\n### Tutorial Architecture\n\nThe complete workflow consists of five main stages:\n\n1. **Development**: Create your agent code locally\n2. **Packaging**: Use `agentrun pack` to prepare the workspace\n3. **Building**: Use `agentrun build` to create container images\n4. **Publishing**: Use `agentrun publish` to deploy to AgentCube\n5. **Invocation**: Use `agentrun invoke` to test your deployed agent\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Development â”‚ --> â”‚   Pack   â”‚ --> â”‚  Build  â”‚ --> â”‚ Publish â”‚ --> â”‚ Invoke â”‚\nâ”‚    Agent    â”‚     â”‚          â”‚     â”‚  Image  â”‚     â”‚   to    â”‚     â”‚ Agent  â”‚\nâ”‚    Code     â”‚     â”‚          â”‚     â”‚         â”‚     â”‚ AgentCubeâ”‚    â”‚        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting this tutorial, ensure you have:\n",
    "\n",
    "* **Python 3.8+** installed\n",
    "* **Docker** installed and running (for local builds)\n",
    "* **AgentRun CLI** installed\n",
    "* Basic understanding of Python and HTTP APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install AgentRun CLI\n",
    "\n",
    "First, let's install the AgentRun CLI tool. You can install it from source or from PyPI (when available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AgentRun CLI from the cli-agentrun directory\n",
    "# Note: Adjust the path based on your setup\n",
    "!pip install -e ../../ --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!agentrun --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "You should see the AgentRun CLI help message showing all available commands:\n",
    "- `pack` - Package agent into standardized workspace\n",
    "- `build` - Build container image\n",
    "- `publish` - Publish agent to AgentCube\n",
    "- `invoke` - Invoke published agent\n",
    "- `status` - Check agent status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Explore the Example Agent\n\nLet's examine the LangChain agent we'll be deploying. This agent provides a practical example of an AI agent that uses LangChain's framework with tool-calling capabilities."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the agent directory structure\n",
    "!ls -la agent/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "main.py          # The main agent code\n",
    "requirements.txt # Python dependencies\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a snippet of the agent code\n",
    "!head -50 agent/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Understanding the Agent\n\nThe LangChain Agent provides four main endpoints:\n\n1. **`GET /`** - Service information and health check\n2. **`GET /health`** - Health check endpoint for container orchestration\n3. **`GET /tools`** - List available tools (Calculator, Weather)\n4. **`POST /invoke`** - Invoke the agent with a prompt\n\nThe agent uses LangChain framework and includes:\n- **Calculator Tool**: Performs basic mathematical calculations (e.g., \"2 + 2\", \"10 * 5\")\n- **Weather Tool**: Provides mock weather information for cities (Shanghai, Beijing, New York, London)\n- **Mock Mode**: Works without OpenAI API key for testing purposes\n- **Conversational Memory**: Maintains context across interactions\n- **FastAPI**: Modern async web framework for HTTP endpoints"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test the Agent Locally (Optional)\n",
    "\n",
    "Before deploying, you can test the agent locally to ensure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the agent in the background (this cell will start a background process)\n",
    "import subprocess\n",
    "import time\n",
    "import signal\n",
    "\n",
    "# Start the agent\n",
    "proc = subprocess.Popen(\n",
    "    ['python', 'agent/main.py'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Agent started on port 8080\")\n",
    "print(\"PID:\", proc.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the agent with sample requests\nimport requests\nimport json\n\ntry:\n    # Test health endpoint\n    response = requests.get('http://localhost:8080/health')\n    print(\"Health Check:\")\n    print(json.dumps(response.json(), indent=2))\n    print()\n    \n    # Test tools listing\n    response = requests.get('http://localhost:8080/tools')\n    print(\"Available Tools:\")\n    print(json.dumps(response.json(), indent=2))\n    print()\n    \n    # Test agent invocation with calculator\n    response = requests.post(\n        'http://localhost:8080/invoke',\n        json={'prompt': 'What is 25 multiplied by 4?'}\n    )\n    print(\"Agent Response (Calculator Query):\")\n    print(json.dumps(response.json(), indent=2))\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Make sure the agent is running on port 8080\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```json\nHealth Check:\n{\n  \"status\": \"healthy\"\n}\n\nAvailable Tools:\n{\n  \"tools\": [\n    {\n      \"name\": \"Calculator\",\n      \"description\": \"Useful for performing mathematical calculations. Input should be a mathematical expression like '2 + 2' or '10 * 5'.\"\n    },\n    {\n      \"name\": \"Weather\",\n      \"description\": \"Useful for getting weather information for a city. Input should be a city name like 'Shanghai' or 'New York'.\"\n    }\n  ]\n}\n\nAgent Response (Calculator Query):\n{\n  \"response\": \"[Mock Response] Received prompt: 'What is 25 multiplied by 4?'. This would normally use the Calculator tool to perform the calculation. (Set OPENAI_API_KEY environment variable for real agent responses)\",\n  \"success\": true,\n  \"error\": null\n}\n```\n\nNote: Without an OpenAI API key, the agent runs in mock mode. With a valid API key, it will use LangChain to process requests and call the appropriate tools."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the local agent\n",
    "try:\n",
    "    proc.terminate()\n",
    "    proc.wait(timeout=5)\n",
    "    print(\"Agent stopped\")\n",
    "except:\n",
    "    proc.kill()\n",
    "    print(\"Agent killed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Package the Agent with `agentrun pack`\n",
    "\n",
    "Now let's package our agent using the AgentRun CLI. The `pack` command:\n",
    "\n",
    "- Validates the agent structure\n",
    "- Creates `agent_metadata.yaml` configuration file\n",
    "- Generates a `Dockerfile` automatically\n",
    "- Prepares the workspace for building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Package the agent\n!agentrun pack \\\n    -f agent \\\n    --agent-name \"langchain-agent\" \\\n    --description \"A LangChain agent with Calculator and Weather tools\" \\\n    --language \"python\" \\\n    --entrypoint \"python main.py\" \\\n    --port 8080 \\\n    --build-mode \"local\" \\\n    --verbose"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully packaged agent: langchain-agent\nğŸ“ Workspace: /path/to/agent\nğŸ“„ Metadata: /path/to/agent/agent_metadata.yaml\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Generated Files\n",
    "\n",
    "After packaging, let's examine the generated files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the generated agent_metadata.yaml\n",
    "!cat agent/agent_metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```yaml\nagent_name: langchain-agent\ndescription: A LangChain agent with Calculator and Weather tools\nlanguage: python\nentrypoint: python main.py\nport: 8080\nbuild_mode: local\nrequirements_file: requirements.txt\n```\n\nThis metadata file is the central configuration for your agent. It defines:\n- **agent_name**: Unique identifier for your agent\n- **description**: Human-readable description\n- **language**: Programming language (python, java)\n- **entrypoint**: Command to start the agent\n- **port**: Port the agent listens on\n- **build_mode**: Build strategy (local or cloud)\n- **requirements_file**: Dependencies file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the generated Dockerfile\n",
    "!cat agent/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "The Dockerfile is automatically generated based on your agent's language and configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Agent Image with `agentrun build`\n",
    "\n",
    "Now let's build a container image for our agent. The `build` command:\n",
    "\n",
    "- Builds a Docker image from your agent workspace\n",
    "- Supports local Docker builds and cloud builds\n",
    "- Updates metadata with build information\n",
    "- Provides detailed build progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the agent image\n",
    "!agentrun build -f agent --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully built agent image: langchain-agent\nğŸ·ï¸  Tag: latest\nğŸ“ Size: ~200MB\n```\n\nThe build process:\n1. Reads the Dockerfile and agent_metadata.yaml\n2. Builds the Docker image locally\n3. Tags the image with the agent name\n4. Updates metadata with build information"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify the Docker image was created\n!docker images | grep langchain-agent"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nlangchain-agent    latest    abc123def456    1 minute ago    200MB\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Built Container (Optional)\n",
    "\n",
    "Before publishing to AgentCube, you can test the container locally to ensure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run the container locally\n!docker run -d -p 8080:8080 --name langchain-agent-test langchain-agent:latest\n\nimport time\ntime.sleep(3)  # Wait for container to start\nprint(\"Container started!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the containerized agent\nimport requests\nimport json\n\ntry:\n    response = requests.post(\n        'http://localhost:8080/invoke',\n        json={'prompt': 'What is the weather in Shanghai?'}\n    )\n    print(\"Containerized Agent Response:\")\n    print(json.dumps(response.json(), indent=2))\nexcept Exception as e:\n    print(f\"Error: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```json\n{\n  \"response\": \"[Mock Response] Received prompt: 'What is the weather in Shanghai?'. This would normally use the Weather tool to fetch weather information. (Set OPENAI_API_KEY environment variable for real agent responses)\",\n  \"success\": true,\n  \"error\": null\n}\n```\n\nNote: The agent is running in mock mode. With a valid OpenAI API key, it would use the Weather tool to provide weather information."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Stop and remove the test container\n!docker stop langchain-agent-test\n!docker rm langchain-agent-test"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Publish the Agent with `agentrun publish`\n",
    "\n",
    "Now let's publish our agent to AgentCube. The `publish` command:\n",
    "\n",
    "- Registers the agent with AgentCube\n",
    "- Pushes the Docker image to a registry (if using cloud mode)\n",
    "- Creates a deployment endpoint\n",
    "- Updates metadata with deployment information\n",
    "\n",
    "**Note**: In the MVP version, the publish command simulates AgentCube integration for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Publish the agent to AgentCube\n!agentrun publish \\\n    -f agent \\\n    --version \"v1.0.0\" \\\n    --image-url \"docker.io/myorg/langchain-agent\" \\\n    --description \"LangChain agent with Calculator and Weather tools\" \\\n    --verbose"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully published agent: langchain-agent\nğŸ†” Agent ID: agent-abc123\nğŸŒ Endpoint: https://api.agentcube.example.com/agents/agent-abc123/invoke\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Publish Process\n",
    "\n",
    "The publish command:\n",
    "1. Validates that the agent has been built\n",
    "2. Tags and pushes the image to the specified registry\n",
    "3. Registers the agent with AgentCube API\n",
    "4. Receives an agent ID and endpoint URL\n",
    "5. Updates the metadata with deployment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the updated metadata after publishing\n",
    "!cat agent/agent_metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```yaml\nagent_name: langchain-agent\ndescription: LangChain agent with Calculator and Weather tools\nlanguage: python\nentrypoint: python main.py\nport: 8080\nbuild_mode: local\nrequirements_file: requirements.txt\nversion: v1.0.0\nagent_id: agent-abc123\nagent_endpoint: https://api.agentcube.example.com/agents/agent-abc123/invoke\nimage:\n  repository_url: docker.io/myorg/langchain-agent\n  tag: latest\n  build_mode: local\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Check Agent Status with `agentrun status`\n",
    "\n",
    "You can check the status of your published agent at any time using the `status` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check agent status\n",
    "!agentrun status -f agent --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                       Agent Status                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Property   â”‚ Value                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Agent Name â”‚ langchain-agent                                   â”‚\nâ”‚ Agent ID   â”‚ agent-abc123                                      â”‚\nâ”‚ Version    â”‚ v1.0.0                                            â”‚\nâ”‚ Language   â”‚ python                                            â”‚\nâ”‚ Build Mode â”‚ local                                             â”‚\nâ”‚ Endpoint   â”‚ https://api.agentcube.example.com/agents/...     â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Invoke the Published Agent with `agentrun invoke`\n",
    "\n",
    "Finally, let's test our published agent by invoking it with a sample payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Invoke the agent with a calculator query\n!agentrun invoke \\\n    -f agent \\\n    --payload '{\"prompt\": \"What is 15 plus 27?\"}' \\\n    --verbose"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"[Mock Response] Received prompt: 'What is 15 plus 27?'. This would normally use the Calculator tool to perform the calculation. (Set OPENAI_API_KEY environment variable for real agent responses)\",\n  \"success\": true,\n  \"error\": null\n}\n```\n\nWith a valid OpenAI API key, the response would be:\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"The result of 15 plus 27 is 42.\",\n  \"success\": true,\n  \"error\": null\n}\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Invoke with a weather query\n!agentrun invoke \\\n    -f agent \\\n    --payload '{\"prompt\": \"What is the weather like in Beijing?\"}' \\\n    --verbose"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"[Mock Response] Received prompt: 'What is the weather like in Beijing?'. This would normally use the Weather tool to fetch weather information. (Set OPENAI_API_KEY environment variable for real agent responses)\",\n  \"success\": true,\n  \"error\": null\n}\n```\n\nWith a valid OpenAI API key, the agent would use the Weather tool and respond:\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"The weather in Beijing is Cloudy, 18Â°C, with 45% humidity.\",\n  \"success\": true,\n  \"error\": null\n}\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Invoke with a general query\n!agentrun invoke \\\n    -f agent \\\n    --payload '{\"prompt\": \"Tell me about the available tools.\"}' \\\n    --verbose"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Expected Output:**\n\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"[Mock Response] Received prompt: 'Tell me about the available tools.'. This would normally process your request using LangChain with OpenAI. (Set OPENAI_API_KEY environment variable for real agent responses)\",\n  \"success\": true,\n  \"error\": null\n}\n```\n\nWith a valid OpenAI API key, the agent would provide information about its tools:\n```\nâœ… Successfully invoked agent\nğŸ“¤ Response: {\n  \"response\": \"I have access to two tools: a Calculator for performing mathematical calculations, and a Weather tool for getting weather information for various cities.\",\n  \"success\": true,\n  \"error\": null\n}\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Using Python SDK (Advanced)\n",
    "\n",
    "AgentRun CLI also provides a Python SDK for programmatic access. This is useful for CI/CD pipelines and automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example of using the Python SDK\nfrom pathlib import Path\nfrom agentrun.runtime.pack_runtime import PackRuntime\nfrom agentrun.runtime.build_runtime import BuildRuntime\nfrom agentrun.runtime.publish_runtime import PublishRuntime\nfrom agentrun.runtime.invoke_runtime import InvokeRuntime\n\n# Initialize runtimes\nworkspace_path = Path(\"agent\").resolve()\n\n# Pack the agent\npack_runtime = PackRuntime(verbose=True)\npack_result = pack_runtime.pack(\n    workspace_path,\n    agent_name=\"langchain-agent-sdk\",\n    description=\"LangChain agent packaged using Python SDK\"\n)\nprint(f\"Packed: {pack_result['agent_name']}\")\n\n# Build the agent\nbuild_runtime = BuildRuntime(verbose=True)\nbuild_result = build_runtime.build(workspace_path)\nprint(f\"Built: {build_result['image_name']}\")\n\n# Publish the agent\npublish_runtime = PublishRuntime(verbose=True)\npublish_result = publish_runtime.publish(\n    workspace_path,\n    version=\"v1.0.0\",\n    image_url=\"docker.io/myorg/langchain-agent-sdk\"\n)\nprint(f\"Published: {publish_result['agent_id']}\")\n\n# Invoke the agent\ninvoke_runtime = InvokeRuntime(verbose=True)\ninvoke_result = invoke_runtime.invoke(\n    workspace_path,\n    {\"prompt\": \"What is 10 times 5?\"},\n    {}\n)\nprint(f\"Invocation result: {invoke_result}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this tutorial, we covered the complete AgentRun CLI workflow:\n",
    "\n",
    "1. âœ… **Installed** AgentRun CLI\n",
    "2. âœ… **Explored** a practical sentiment analysis agent\n",
    "3. âœ… **Tested** the agent locally\n",
    "4. âœ… **Packaged** the agent with `agentrun pack`\n",
    "5. âœ… **Built** a container image with `agentrun build`\n",
    "6. âœ… **Published** the agent with `agentrun publish`\n",
    "7. âœ… **Checked** status with `agentrun status`\n",
    "8. âœ… **Invoked** the agent with `agentrun invoke`\n",
    "9. âœ… **Used** the Python SDK for programmatic access\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "#### 1. Project Structure\n",
    "```\n",
    "my-agent/\n",
    "â”œâ”€â”€ main.py              # Agent entrypoint\n",
    "â”œâ”€â”€ requirements.txt     # Dependencies\n",
    "â”œâ”€â”€ README.md           # Documentation\n",
    "â”œâ”€â”€ agent_metadata.yaml # Generated by agentrun pack\n",
    "â””â”€â”€ Dockerfile          # Generated by agentrun pack\n",
    "```\n",
    "\n",
    "#### 2. Agent Development\n",
    "- **Test locally first** before packaging and deploying\n",
    "- **Implement health checks** at `/health` endpoint\n",
    "- **Support both `text` and `prompt`** fields for flexibility\n",
    "- **Return structured JSON** responses\n",
    "- **Handle errors gracefully** with proper HTTP status codes\n",
    "- **Add logging** for debugging and monitoring\n",
    "\n",
    "#### 3. Metadata Configuration\n",
    "- **Use descriptive names** for your agents\n",
    "- **Provide clear descriptions** to help users understand your agent\n",
    "- **Specify correct entrypoint** and port\n",
    "- **Choose appropriate build mode** (local for development, cloud for production)\n",
    "- **Use semantic versioning** for version numbers (v1.0.0, v1.1.0, etc.)\n",
    "\n",
    "#### 4. Building and Deployment\n",
    "- **Test container locally** before publishing\n",
    "- **Use proper image naming** conventions (organization/agent-name)\n",
    "- **Tag images with versions** for easier rollback\n",
    "- **Keep images small** by using slim base images\n",
    "- **Document dependencies** clearly in requirements.txt\n",
    "\n",
    "#### 5. CI/CD Integration\n",
    "- **Use Python SDK** for automation\n",
    "- **Implement automated testing** before deployment\n",
    "- **Version control** your agent code and metadata\n",
    "- **Use environment variables** for configuration\n",
    "- **Set up monitoring** for production agents\n",
    "\n",
    "### Command Reference\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|----------|\n",
    "| `agentrun pack` | Package agent workspace | `agentrun pack -f ./agent --agent-name my-agent` |\n",
    "| `agentrun build` | Build container image | `agentrun build -f ./agent --verbose` |\n",
    "| `agentrun publish` | Publish to AgentCube | `agentrun publish -f ./agent --version v1.0.0` |\n",
    "| `agentrun invoke` | Test deployed agent | `agentrun invoke -f ./agent --payload '{\"text\": \"test\"}'` |\n",
    "| `agentrun status` | Check agent status | `agentrun status -f ./agent` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now that you understand the basics, you can:\n",
    "\n",
    "1. **Enhance the sentiment agent** with more sophisticated NLP capabilities\n",
    "2. **Add authentication** using custom headers\n",
    "3. **Implement streaming responses** for long-running tasks\n",
    "4. **Create multi-agent systems** with agent-to-agent communication\n",
    "5. **Integrate with external APIs** and services\n",
    "6. **Build custom agents** for your specific use cases\n",
    "7. **Explore cloud build mode** for serverless deployments\n",
    "8. **Set up monitoring and logging** for production agents\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [AgentRun CLI Documentation](../../README.md)\n",
    "- [Quick Start Guide](../../QUICKSTART.md)\n",
    "- [Example Agents](../../examples/)\n",
    "- [AgentCube Main Project](https://github.com/volcano-sh/agentcube)\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "If you encounter issues or have questions:\n",
    "\n",
    "- Run commands with `--verbose` flag for detailed logging\n",
    "- Check `agentrun <command> --help` for command-specific help\n",
    "- Review the [troubleshooting guide](../../QUICKSTART.md#troubleshooting)\n",
    "- Open an issue on [GitHub](https://github.com/volcano-sh/agentcube/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to clean up the resources created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Remove Docker images\n!docker rmi langchain-agent:latest\n!docker rmi langchain-agent-sdk:latest"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove generated files (optional)\n",
    "!rm -f agent/agent_metadata.yaml\n",
    "!rm -f agent/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! ğŸ‰\n",
    "\n",
    "You've successfully completed the AgentRun CLI tutorial and learned how to develop, package, build, publish, and invoke AI agents using AgentRun CLI!\n",
    "\n",
    "Happy agent building! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}