{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Agent with MCP Server Integration\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this tutorial, you will learn how to build and deploy a distributed AI agent system using:\n",
        "- **MCP Server**: A Model Context Protocol server providing utility tools\n",
        "- **LangChain Agent**: An agent that consumes and orchestrates MCP server tools\n",
        "- **AgentRun CLI**: To deploy both components separately to local Kubernetes\n",
        "\n",
        "This demonstrates a microservices architecture where the tool provider (MCP server) and the agent orchestrator (LangChain agent) are deployed and scaled independently.\n",
        "\n",
        "### Tutorial Details\n",
        "\n",
        "| Information         | Details                                                                      |\n",
        "|:--------------------|:-----------------------------------------------------------------------------|\n",
        "| Tutorial type       | Advanced Integration                                                         |\n",
        "| Agent type          | LangChain Agent + MCP Server                                                 |\n",
        "| Framework           | LangChain + MCP + FastAPI                                                    |\n",
        "| Language            | Python 3.8+                                                                  |\n",
        "| Tutorial components | MCP server creation, LangChain integration, distributed deployment           |\n",
        "| Tutorial vertical   | Cross-vertical                                                               |\n",
        "| Example complexity  | Intermediate                                                                 |\n",
        "| Tools used          | AgentRun CLI, Docker, Kubernetes, LangChain, MCP                             |\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "* How to create an MCP server with multiple useful tools\n",
        "* How to integrate MCP servers with LangChain agents\n",
        "* How to deploy distributed agent systems using AgentRun CLI\n",
        "* How agents and tools can communicate across services\n",
        "* Best practices for microservices-based AI architectures\n",
        "\n",
        "### Tutorial Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    User Request                             â”‚\n",
        "â”‚                         â”‚                                   â”‚\n",
        "â”‚                         â–¼                                   â”‚\n",
        "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
        "â”‚            â”‚  LangChain Agent       â”‚                       â”‚\n",
        "â”‚            â”‚  (Port 8080)           â”‚                       â”‚\n",
        "â”‚            â”‚                        â”‚                       â”‚\n",
        "â”‚            â”‚  - Receives prompts    â”‚                       â”‚\n",
        "â”‚            â”‚  - Orchestrates tools  â”‚                       â”‚\n",
        "â”‚            â”‚  - Returns responses   â”‚                       â”‚\n",
        "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
        "â”‚                         â”‚                                   â”‚\n",
        "â”‚                         â”‚ HTTP/MCP                          â”‚\n",
        "â”‚                         â–¼                                   â”‚\n",
        "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
        "â”‚            â”‚  MCP Server            â”‚                       â”‚\n",
        "â”‚            â”‚  (Port 8000)           â”‚                       â”‚\n",
        "â”‚            â”‚                        â”‚                       â”‚\n",
        "â”‚            â”‚  Tools:                â”‚                       â”‚\n",
        "â”‚            â”‚  - Calculator          â”‚                       â”‚\n",
        "â”‚            â”‚  - File Operations     â”‚                       â”‚\n",
        "â”‚            â”‚  - DateTime Utils      â”‚                       â”‚\n",
        "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
        "â”‚                                                              â”‚\n",
        "â”‚         Both deployed separately to Kubernetes              â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Key Features\n",
        "\n",
        "* **Distributed Architecture**: Agent and tools deployed separately\n",
        "* **MCP Protocol**: Standard protocol for tool communication\n",
        "* **LangChain Integration**: Seamless integration with LangChain ecosystem\n",
        "* **Multiple Tool Categories**: Calculator, file operations, and datetime utilities\n",
        "* **Production-Ready**: Deployed to Kubernetes with proper service discovery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before starting this tutorial, ensure you have:\n",
        "\n",
        "* **Python 3.8+** installed\n",
        "* **Docker** installed and running\n",
        "* **Kubernetes** (Docker Desktop with Kubernetes enabled, or minikube)\n",
        "* **AgentRun CLI** installed\n",
        "* Basic understanding of:\n",
        "  - Python programming\n",
        "  - REST APIs\n",
        "  - LangChain agents (recommended)\n",
        "  - Model Context Protocol (MCP) basics (recommended)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "First, let's install AgentRun CLI and verify it's working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install AgentRun CLI\n",
        "%pip install -e ../ --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify installation\n",
        "!agentrun --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Explore the MCP Server\n",
        "\n",
        "Let's examine the MCP server that provides utility tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View MCP server structure\n",
        "!ls -la mcp_server/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View MCP server tools (first 100 lines)\n",
        "!head -100 mcp_server/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the MCP Server\n",
        "\n",
        "The MCP server provides **8 utility tools** across three categories:\n",
        "\n",
        "**Calculator Tools:**\n",
        "1. `calculate`: Evaluate mathematical expressions (e.g., \"2 + 2\", \"10 * 5\")\n",
        "2. `power`: Calculate base raised to exponent (e.g., power(2, 3) = 8)\n",
        "\n",
        "**File Operation Tools:**\n",
        "3. `write_file`: Write content to a file in the workspace\n",
        "4. `read_file`: Read content from a file\n",
        "5. `list_files`: List all files in the workspace\n",
        "\n",
        "**DateTime Tools:**\n",
        "6. `get_current_time`: Get current date and time (with timezone support)\n",
        "7. `format_timestamp`: Convert Unix timestamp to formatted date string\n",
        "\n",
        "**Info Tools:**\n",
        "8. `server_info`: Get MCP server information\n",
        "\n",
        "The server uses:\n",
        "- **FastMCP**: Modern MCP server framework\n",
        "- **Stateless HTTP**: For compatibility with AgentRun deployment\n",
        "- **Port 8000**: Standard MCP server port"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Explore the LangChain Agent\n",
        "\n",
        "Now let's examine the LangChain agent that will consume the MCP server tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View agent structure\n",
        "!ls -la agent/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View agent code (first 80 lines)\n",
        "!head -80 agent/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the LangChain Agent\n",
        "\n",
        "The LangChain agent:\n",
        "- **Connects to MCP Server**: Uses MCP client to discover and call tools\n",
        "- **Converts MCP to LangChain**: Transforms MCP tools into LangChain-compatible tools\n",
        "- **Orchestrates Tool Calls**: Uses LangChain's ReAct agent to decide when and how to use tools\n",
        "- **Exposes REST API**: Provides FastAPI endpoints for interaction\n",
        "\n",
        "Key features:\n",
        "- **Mock Mode**: Works without OpenAI API key for testing\n",
        "- **Production Mode**: Uses OpenAI for real agent reasoning (when API key is set)\n",
        "- **Service Discovery**: Automatically connects to MCP server via environment variables\n",
        "- **Health Checks**: Provides health and status endpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test MCP Server Locally (Optional)\n",
        "\n",
        "Before deploying, let's test the MCP server locally to ensure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install MCP server dependencies\n",
        "%pip install -r mcp_server/requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start MCP server in background\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "mcp_proc = subprocess.Popen(\n",
        "    ['python', 'mcp_server/main.py'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "time.sleep(3)\n",
        "print(f\"MCP Server started (PID: {mcp_proc.pid})\")\n",
        "print(\"Server running on http://localhost:8000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test MCP server with a simple client\n",
        "import asyncio\n",
        "from datetime import timedelta\n",
        "from mcp import ClientSession\n",
        "from mcp.client.streamable_http import streamablehttp_client\n",
        "\n",
        "async def test_mcp_server():\n",
        "    mcp_url = \"http://localhost:8000/mcp\"\n",
        "    headers = {}\n",
        "    \n",
        "    async with streamablehttp_client(mcp_url, headers, timeout=timedelta(seconds=30), terminate_on_close=False) as (\n",
        "        read_stream, write_stream, _\n",
        "    ):\n",
        "        async with ClientSession(read_stream, write_stream) as session:\n",
        "            await session.initialize()\n",
        "            \n",
        "            # List available tools\n",
        "            tool_result = await session.list_tools()\n",
        "            print(\"\\nğŸ“‹ Available Tools from MCP Server:\")\n",
        "            print(\"=\" * 50)\n",
        "            for tool in tool_result.tools:\n",
        "                print(f\"ğŸ”§ {tool.name}: {tool.description}\")\n",
        "            \n",
        "            # Test calculator tool\n",
        "            print(\"\\nğŸ§ª Testing Calculator Tool:\")\n",
        "            print(\"=\" * 50)\n",
        "            result = await session.call_tool(name=\"calculate\", arguments={\"expression\": \"15 + 27\"})\n",
        "            print(f\"calculate('15 + 27') = {result.content[0].text}\")\n",
        "            \n",
        "            # Test current time tool\n",
        "            print(\"\\nğŸ• Testing DateTime Tool:\")\n",
        "            print(\"=\" * 50)\n",
        "            result = await session.call_tool(name=\"get_current_time\", arguments={})\n",
        "            print(f\"get_current_time() = {result.content[0].text}\")\n",
        "\n",
        "try:\n",
        "    await test_mcp_server()\n",
        "    print(\"\\nâœ… MCP Server is working correctly!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ Error testing MCP server: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop MCP server\n",
        "try:\n",
        "    mcp_proc.terminate()\n",
        "    mcp_proc.wait(timeout=5)\n",
        "    print(\"MCP Server stopped\")\n",
        "except:\n",
        "    mcp_proc.kill()\n",
        "    print(\"MCP Server killed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "\n",
        "You should see:\n",
        "- 8 tools listed from the MCP server\n",
        "- Successful calculation result (42)\n",
        "- Current timestamp\n",
        "\n",
        "This confirms the MCP server is working correctly before deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Package the MCP Server\n",
        "\n",
        "Now let's package the MCP server using AgentRun CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Package MCP server\n",
        "!agentrun pack \\\n",
        "    -f mcp_server \\\n",
        "    --agent-name \"mcp-utility-server\" \\\n",
        "    --description \"MCP server with calculator, file ops, and datetime tools\" \\\n",
        "    --language \"python\" \\\n",
        "    --entrypoint \"python main.py\" \\\n",
        "    --port 8000 \\\n",
        "    --build-mode \"local\" \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "âœ… Successfully packaged agent: mcp-utility-server\n",
        "ğŸ“ Workspace: /path/to/mcp_server\n",
        "ğŸ“„ Metadata: /path/to/mcp_server/agent_metadata.yaml\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View generated metadata\n",
        "!cat mcp_server/agent_metadata.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Build the MCP Server Image\n",
        "\n",
        "Build a Docker image for the MCP server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build MCP server image\n",
        "!agentrun build -f mcp_server --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "âœ… Successfully built agent image: mcp-utility-server:latest\n",
        "ğŸ·ï¸  Tag: mcp-utility-server:latest\n",
        "ğŸ“ Size: ~XXX MB\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify Docker image\n",
        "!docker images | grep mcp-utility-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Publish MCP Server to Kubernetes\n",
        "\n",
        "Deploy the MCP server to local Kubernetes cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Publish MCP server to Kubernetes\n",
        "!agentrun publish \\\n",
        "    -f mcp_server \\\n",
        "    --version \"v1.0.0\" \\\n",
        "    --image-url \"mcp-utility-server:latest\" \\\n",
        "    --description \"MCP server with utility tools\" \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "âœ… Successfully published agent: mcp-utility-server\n",
        "ğŸŒ Service URL: http://localhost:XXXXX\n",
        "ğŸ“Š Kubernetes Deployment: mcp-utility-server in namespace agentrun\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check MCP server status\n",
        "!agentrun status -f mcp_server --use-k8s --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the MCP server service URL from metadata\n",
        "import yaml\n",
        "\n",
        "with open('mcp_server/agent_metadata.yaml', 'r') as f:\n",
        "    mcp_metadata = yaml.safe_load(f)\n",
        "\n",
        "mcp_service_url = mcp_metadata.get('k8s_deployment', {}).get('service_url', 'http://localhost:8000')\n",
        "mcp_server_endpoint = f\"{mcp_service_url}/mcp\"\n",
        "\n",
        "print(f\"MCP Server Service URL: {mcp_service_url}\")\n",
        "print(f\"MCP Server Endpoint: {mcp_server_endpoint}\")\n",
        "\n",
        "# Save for agent configuration\n",
        "with open('.mcp_server_url.txt', 'w') as f:\n",
        "    f.write(mcp_server_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Test Deployed MCP Server\n",
        "\n",
        "Verify the MCP server is working in Kubernetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test deployed MCP server\n",
        "import asyncio\n",
        "from datetime import timedelta\n",
        "from mcp import ClientSession\n",
        "from mcp.client.streamable_http import streamablehttp_client\n",
        "\n",
        "async def test_deployed_mcp():\n",
        "    # Read MCP server URL\n",
        "    with open('.mcp_server_url.txt', 'r') as f:\n",
        "        mcp_url = f.read().strip()\n",
        "    \n",
        "    print(f\"Testing MCP server at: {mcp_url}\")\n",
        "    headers = {}\n",
        "    \n",
        "    try:\n",
        "        async with streamablehttp_client(mcp_url, headers, timeout=timedelta(seconds=30), terminate_on_close=False) as (\n",
        "            read_stream, write_stream, _\n",
        "        ):\n",
        "            async with ClientSession(read_stream, write_stream) as session:\n",
        "                await session.initialize()\n",
        "                \n",
        "                # List tools\n",
        "                tool_result = await session.list_tools()\n",
        "                print(f\"\\nâœ… MCP Server is running with {len(tool_result.tools)} tools\")\n",
        "                print(\"\\nAvailable tools:\")\n",
        "                for tool in tool_result.tools:\n",
        "                    print(f\"  - {tool.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error connecting to MCP server: {e}\")\n",
        "        print(\"Make sure the MCP server is deployed and accessible\")\n",
        "\n",
        "await test_deployed_mcp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Configure Agent with MCP Server URL\n",
        "\n",
        "Before packaging the agent, we need to configure it with the MCP server URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create agent environment configuration\n",
        "with open('.mcp_server_url.txt', 'r') as f:\n",
        "    mcp_url = f.read().strip()\n",
        "\n",
        "# For Kubernetes deployment, we'll use the service name\n",
        "# The service name will be mcp-utility-server in the agentrun namespace\n",
        "k8s_mcp_url = \"http://mcp-utility-server.agentrun.svc.cluster.local:8000/mcp\"\n",
        "\n",
        "print(f\"Local MCP URL: {mcp_url}\")\n",
        "print(f\"Kubernetes MCP URL: {k8s_mcp_url}\")\n",
        "print(\"\\nThe agent will use the Kubernetes service URL when deployed to k8s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Package the LangChain Agent\n",
        "\n",
        "Now let's package the LangChain agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Package the agent\n",
        "!agentrun pack \\\n",
        "    -f agent \\\n",
        "    --agent-name \"langchain-mcp-agent\" \\\n",
        "    --description \"LangChain agent that uses MCP server tools\" \\\n",
        "    --language \"python\" \\\n",
        "    --entrypoint \"python main.py\" \\\n",
        "    --port 8080 \\\n",
        "    --build-mode \"local\" \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Build the Agent Image\n",
        "\n",
        "Build a Docker image for the LangChain agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build agent image\n",
        "!agentrun build -f agent --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify Docker image\n",
        "!docker images | grep langchain-mcp-agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Publish Agent to Kubernetes\n",
        "\n",
        "Deploy the LangChain agent to Kubernetes with MCP server URL configured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Publish agent to Kubernetes\n",
        "# Note: The agent will automatically connect to the MCP server via Kubernetes service discovery\n",
        "!agentrun publish \\\n",
        "    -f agent \\\n",
        "    --version \"v1.0.0\" \\\n",
        "    --image-url \"langchain-mcp-agent:latest\" \\\n",
        "    --description \"LangChain agent with MCP server integration\" \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: In a production environment, you would set environment variables in the Kubernetes deployment to configure the MCP_SERVER_URL. For this tutorial, the agent defaults to connecting to the MCP server service within the cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check agent status\n",
        "!agentrun status -f agent --use-k8s --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Test the Integrated System\n",
        "\n",
        "Now let's test the complete system: agent communicating with MCP server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test agent health\n",
        "!agentrun invoke \\\n",
        "    -f agent \\\n",
        "    --payload '{\"prompt\": \"health check\"}' \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test calculator tool through agent\n",
        "!agentrun invoke \\\n",
        "    -f agent \\\n",
        "    --payload '{\"prompt\": \"Calculate 25 multiplied by 4\"}' \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output (Mock Mode):**\n",
        "```\n",
        "âœ… Successfully invoked agent\n",
        "ğŸ“¤ Response: [Mock Mode] Received prompt: 'Calculate 25 multiplied by 4'.\n",
        "Available tools from MCP server: calculate, power, write_file, read_file, \n",
        "list_files, get_current_time, format_timestamp, server_info.\n",
        "Set OPENAI_API_KEY environment variable for real agent responses.\n",
        "```\n",
        "\n",
        "**Expected Output (Production Mode with OpenAI API key):**\n",
        "```\n",
        "âœ… Successfully invoked agent\n",
        "ğŸ“¤ Response: The result of 25 multiplied by 4 is 100.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test datetime tool\n",
        "!agentrun invoke \\\n",
        "    -f agent \\\n",
        "    --payload '{\"prompt\": \"What is the current time?\"}' \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test file operations\n",
        "!agentrun invoke \\\n",
        "    -f agent \\\n",
        "    --payload '{\"prompt\": \"Write 'Hello from LangChain agent' to a file called greeting.txt\"}' \\\n",
        "    --verbose \\\n",
        "    --use-k8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Verify Kubernetes Deployments\n",
        "\n",
        "Let's verify both services are running properly in Kubernetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Kubernetes pods\n",
        "!kubectl get pods -n agentrun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Kubernetes services\n",
        "!kubectl get services -n agentrun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check deployments\n",
        "!kubectl get deployments -n agentrun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "\n",
        "You should see:\n",
        "- 2 pods running (mcp-utility-server and langchain-mcp-agent)\n",
        "- 2 services exposed\n",
        "- 2 deployments with 1/1 replicas ready\n",
        "\n",
        "This confirms both components are deployed and running in Kubernetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 15: Understanding the Architecture\n",
        "\n",
        "### Microservices Architecture Benefits\n",
        "\n",
        "This distributed architecture provides several advantages:\n",
        "\n",
        "**1. Separation of Concerns**\n",
        "- MCP Server: Focuses solely on providing tools\n",
        "- LangChain Agent: Focuses on orchestration and reasoning\n",
        "\n",
        "**2. Independent Scaling**\n",
        "- Scale the MCP server if tools are heavily used\n",
        "- Scale the agent if there are many user requests\n",
        "- Each component scales based on its own load\n",
        "\n",
        "**3. Reusability**\n",
        "- Multiple agents can connect to the same MCP server\n",
        "- One agent can connect to multiple MCP servers\n",
        "- Tools are centralized and reusable\n",
        "\n",
        "**4. Technology Flexibility**\n",
        "- MCP server could be written in any language\n",
        "- Agent framework can be changed without affecting tools\n",
        "- Each service can use different technology stacks\n",
        "\n",
        "**5. Fault Isolation**\n",
        "- If MCP server fails, agent can handle it gracefully\n",
        "- If agent fails, MCP server continues running\n",
        "- Independent health checks and monitoring\n",
        "\n",
        "### MCP Protocol Benefits\n",
        "\n",
        "**Standardized Communication:**\n",
        "- Well-defined protocol for tool discovery\n",
        "- Consistent tool invocation format\n",
        "- Support for streaming and stateless operation\n",
        "\n",
        "**LangChain Integration:**\n",
        "- Seamless conversion to LangChain tools\n",
        "- Compatible with existing LangChain ecosystem\n",
        "- Works with any LangChain-compatible LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 16: Advanced Usage (Optional)\n",
        "\n",
        "### Adding OpenAI API Key for Production Mode\n",
        "\n",
        "To use the agent in production mode with real reasoning:\n",
        "\n",
        "1. Get an OpenAI API key from https://platform.openai.com/api-keys\n",
        "2. Update the Kubernetes deployment with the API key:\n",
        "\n",
        "```bash\n",
        "kubectl set env deployment/langchain-mcp-agent \\\n",
        "    OPENAI_API_KEY=your-api-key-here \\\n",
        "    -n agentrun\n",
        "```\n",
        "\n",
        "3. The agent will automatically restart and use OpenAI for reasoning\n",
        "\n",
        "### Scaling the Services\n",
        "\n",
        "Scale the MCP server:\n",
        "```bash\n",
        "kubectl scale deployment mcp-utility-server --replicas=3 -n agentrun\n",
        "```\n",
        "\n",
        "Scale the agent:\n",
        "```bash\n",
        "kubectl scale deployment langchain-mcp-agent --replicas=2 -n agentrun\n",
        "```\n",
        "\n",
        "### Adding More Tools to MCP Server\n",
        "\n",
        "To add new tools:\n",
        "1. Add tool functions to `mcp_server/main.py`\n",
        "2. Decorate with `@mcp.tool()`\n",
        "3. Rebuild and redeploy: `agentrun build` and `agentrun publish`\n",
        "4. Restart the agent to discover new tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Best Practices\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "In this tutorial, we covered:\n",
        "\n",
        "1. âœ… **Created an MCP server** with 8 utility tools\n",
        "2. âœ… **Built a LangChain agent** that integrates with MCP server\n",
        "3. âœ… **Deployed both services** separately to Kubernetes\n",
        "4. âœ… **Tested the integrated system** with various tool invocations\n",
        "5. âœ… **Understood microservices architecture** for AI agents\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "#### 1. MCP Server Design\n",
        "- **Group related tools**: Organize tools by category (calculator, file ops, etc.)\n",
        "- **Use stateless HTTP**: Required for AgentRun deployment\n",
        "- **Provide clear descriptions**: Helps agents understand tool purpose\n",
        "- **Handle errors gracefully**: Return informative error messages\n",
        "- **Keep tools focused**: Each tool should do one thing well\n",
        "\n",
        "#### 2. LangChain Agent Integration\n",
        "- **Implement mock mode**: Allows testing without API keys\n",
        "- **Cache tool discovery**: Don't rediscover tools on every request\n",
        "- **Handle connection failures**: Gracefully handle MCP server unavailability\n",
        "- **Use environment variables**: For configuration (MCP URL, API keys)\n",
        "- **Add health checks**: Monitor agent and MCP server health\n",
        "\n",
        "#### 3. Deployment\n",
        "- **Deploy services separately**: Allows independent scaling\n",
        "- **Use Kubernetes service discovery**: For service-to-service communication\n",
        "- **Set resource limits**: Prevent resource exhaustion\n",
        "- **Implement monitoring**: Track both services independently\n",
        "- **Use secrets for API keys**: Don't hardcode sensitive data\n",
        "\n",
        "#### 4. Testing\n",
        "- **Test locally first**: Before deploying to Kubernetes\n",
        "- **Test tools individually**: Verify each tool works correctly\n",
        "- **Test agent integration**: Ensure agent can call all tools\n",
        "- **Test failure scenarios**: What happens if MCP server is down?\n",
        "\n",
        "### Common Patterns\n",
        "\n",
        "**1. Multi-Agent Systems**\n",
        "- Multiple agents sharing one MCP server\n",
        "- Reduces duplication and centralizes tools\n",
        "\n",
        "**2. Agent Chains**\n",
        "- One agent calls another agent\n",
        "- Each agent has different capabilities via different MCP servers\n",
        "\n",
        "**3. Tool Composition**\n",
        "- Multiple MCP servers providing different tool categories\n",
        "- Agent aggregates tools from multiple sources\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Now that you understand MCP server integration, you can:\n",
        "\n",
        "1. **Add custom tools** to the MCP server for your use case\n",
        "2. **Create specialized agents** for different domains\n",
        "3. **Build multi-agent systems** with shared tool infrastructure\n",
        "4. **Implement authentication** for secure tool access\n",
        "5. **Add observability** with logging and metrics\n",
        "6. **Deploy to production** cloud Kubernetes clusters\n",
        "\n",
        "### Additional Resources\n",
        "\n",
        "- [MCP Protocol Specification](https://modelcontextprotocol.io/)\n",
        "- [LangChain Documentation](https://python.langchain.com/)\n",
        "- [AgentRun CLI Documentation](../../QUICKSTART.md)\n",
        "- [FastMCP Documentation](https://github.com/modelcontextprotocol/fastmcp)\n",
        "- [AgentCube Project](https://github.com/volcano-sh/agentcube)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup (Optional)\n",
        "\n",
        "To clean up the resources created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete Kubernetes deployments\n",
        "!kubectl delete deployment langchain-mcp-agent -n agentrun\n",
        "!kubectl delete deployment mcp-utility-server -n agentrun\n",
        "\n",
        "# Delete services\n",
        "!kubectl delete service langchain-mcp-agent -n agentrun\n",
        "!kubectl delete service mcp-utility-server -n agentrun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove Docker images (optional)\n",
        "!docker rmi langchain-mcp-agent:latest\n",
        "!docker rmi mcp-utility-server:latest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove generated files (optional)\n",
        "!rm -f agent/agent_metadata.yaml agent/Dockerfile\n",
        "!rm -f mcp_server/agent_metadata.yaml mcp_server/Dockerfile\n",
        "!rm -f .mcp_server_url.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Congratulations! ğŸ‰\n",
        "\n",
        "You've successfully completed the LangChain Agent with MCP Server tutorial!\n",
        "\n",
        "You now know how to:\n",
        "- âœ… Create MCP servers with custom tools\n",
        "- âœ… Integrate MCP servers with LangChain agents\n",
        "- âœ… Deploy distributed agent systems using AgentRun CLI\n",
        "- âœ… Build microservices architectures for AI agents\n",
        "\n",
        "Happy building! ğŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
